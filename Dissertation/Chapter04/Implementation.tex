%-----------------------------------------------------------------------------------------
\clearpage
\section{Implementation}
%-----------------------------------------------------------------------------------------

\subsection{Tooling}
Implementing a distributed neural network is too large a task to be undertaken
from scratch. Therefore its necessary to used existing tools, to make the
development viable in the time given. This is difficult as not many languages
lend themselves to both distributed systems and neural networks.

To ensure high performance the project could be implemented in C++. While C++ is
often very performant and also has low level bindings for ML libraries such as
TensorFlow. However even the creator of the language sees the need to improve
its ability to improve its distributed performance. \cite{stroustrupInterview}

Python has great tooling for neural networking, such as TensorFlow
\cite{abadi2016tensorflow}, and PyTorch \cite{paszke2019pytorch}. Moreover it
has great support for numerical computing with NumPy \cite{harrisNumpy2020}.
These are performant too, by calling C functions or creating code which is
optimised to run on GPUs to parallelise computation. However due to the Global
Interpreter Lock (GIL) python is infamously bad at concurrency, while its
distributed tooling is implemented in native python code, which lack of speed
and could bottleneck the performance gained from using NumPy and TensorFlow.

Ultimately I decided to use Elixir as the programming language of
implementation. This is because Elixir was designed for developing highly
concurrent distributed systems. It does this by having a uniquely brilliant
concurrency model. As opposed to OOP languages where 'everything is an object'
in Elixir 'everything is a process'. This means the default way of writing the
language enables it to be concurrent and scalable. Elixir also has the ability
to communicate with other Elixir programs over the network using its own
application protocol on top of TCP/IP. Meaning its as easy to communicate with
local processes on your own machine as processes on another machine running an
Elixir program. Its also been used by artificial intelligence researchers before
as the process concurrency models effortlessly lends itself to modelling
neurons. \cite{sherNeuroevolutionThroughErlang} Using Elixirs native float and
arithmetic implementation would be slower than a C++ or a NumPy implementation,
luckily there is a stable package which supports matrix calculations even faster
than those in NumPy called Matrex. \cite{matrex}

The only drawback of using Elixir is at the time of development it didn't have a
strong machine learning library, which means implementing the mathematics of the
neural network myself. While this was a sizeable amount of work to do, it had
the benefit that I didn't to wrestle with an opinionated API such as TensorFlow,
I could create my own API to meet my ends.

\subsection{Neural Network Implementation}
In order to create a distributed neural network. First I needed to create a
basic feed forward network that could operate on a single machine. This network
didn't need to be fully featured, its just a means to make an objectively
comparative performance between RingTMP and a generic parameter server.
Therefore only 2 types of layers were implemented, the hidden layer and the
output layer. The hidden layer is a generic dense layer similar to the kind you
would find in any other neural network library. It pipes the result of a matrix
multiplication into a ReLU activation function. The output layer performs matrix
multiplication before applying the softmax function. Within this section I will
explain in more detail how the neural network was implemented from scratch and the
mathematics behind its function.

\subsubsection{Forward Propagation}
<<Insert neural network here>>
\par
Neural networks are composed of layers, each layer is composed of neurons.
Numerical inputs are inserted through the input layer, forward propagate through
the network and push numerical results to the output layer. For our purposes
each neuron in the output layer represents a different category, the value of
that neuron is the probability the given input belong to that category.


% need to explain the components of a neuron
Each neuron holds a value, called an activation. Each layer has a bias and a
collection of neurons. Between the layers every neuron in one layer connects to
every other neuron in the next layer, every connection has an associated value
called a weight. To calculate the weight of a single neuron in the next layer
you must multiply the activations of the previous layer with the weights
connected to the neuron in question, then sum the values, add the bias, then
apply the activation function to that value.

this weight is used
to along with the activation function to calculate the activation of the node in
the next network. 