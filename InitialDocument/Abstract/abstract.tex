% ************************** Thesis Abstract *****************************
\null\vspace{\fill}
\renewcommand{\abstractname}{\large Abstract}
\begin{abstract}
\vspace{2cm}

More data than ever is being produced by low power devices such as smart phones
and Internet of Things (IoT) devices at the network edge. The data being
produced is so enormous it would be infeasible to send it to a centralised
location. Instead models can be trained from data distributed across multiple
edge nodes, with machine learning algorithms being performed locally. In this
paper I explore training multiple low power devices using a new distributed
machine learning paradigm \textit{RingTMP}. This paradigm focuses  on low power usage
and power efficiency while having the capacity for larger models than
comparative systems.
\end{abstract}
\vspace{\fill}
